{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform function is created to transform the table names with the given requirements.\n",
    "def transform(table):\n",
    "    table = table.lower()\n",
    "    table = table.replace(\" \",\"_\")\n",
    "    table = table.replace(\"-\",\"_\")\n",
    "    table = table.replace(\"%\",\"pct\")\n",
    "    table = table.replace(\"/\",\"_\")\n",
    "    if table[0].isalpha() == False:\n",
    "        table = \"t_\" + table\n",
    "    return table    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This cell downloads the medicare compare data, unzips and extracts all the file to the staging directory.\n",
    "import requests, zipfile, io\n",
    "url = 'https://data.medicare.gov/views/bg9k-emty/files/0a9879e0-3312-4719-a1db-39fd114890f1? \\\n",
    "       content_type=application%2Fzip%3B%20charset%3Dbinary&filename=Hospital_Revised_Flatfiles.zip'\n",
    "request = requests.get(url)\n",
    "file = zipfile.ZipFile(io.BytesIO(request.content))\n",
    "file.extractall('staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This cell reads all the files from staging directory and converts them to utf-8 from cp1252.\n",
    "import os \n",
    "import glob\n",
    "import pandas as pd\n",
    "# glob method allows us to keep the path name machine independent\n",
    "files = glob.glob(os.path.join(\"staging\" + \"/*.csv\"))\n",
    "\n",
    "dict_ = {}\n",
    "for file in files:\n",
    "    dict_[file] = pd.read_csv(file, header=0, encoding='cp1252').dropna(axis = 1 , how = 'all')\n",
    "    \n",
    "\n",
    "for file in dict_:\n",
    "    dict_[file].to_csv(file, encoding='utf-8')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "dir_path = os.path.abspath(os.path.realpath('staging'))\n",
    "#Since \"FY2015_Percent_Change_in_Medicare_Payments.csv\" it is removed from the staging direcotry.\n",
    "os.remove(os.path.join(dir_path,'FY2015_Percent_Change_in_Medicare_Payments.csv'))\n",
    "# the for loop scans all the existing files in the folder and renames them to the required criteria .\n",
    "for root,dirs,files in os.walk(dir_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            new_file = file\n",
    "            new_file = transform(new_file)\n",
    "            os.replace(os.path.join(root,file),os.path.join(root,new_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using sqlite3 for processing all the data.\n",
    "#Created DB named medicare_hospital_compare.\n",
    "import sqlite3\n",
    "connex = sqlite3.connect('medicare_hospital_compare.db')\n",
    "cur = connex.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reads all the files one by one into a dataframe.\n",
    "#Checks the format of the column and converts them as per requirement for all the files.\n",
    "#Adds the data to the database using database.to_sql.\n",
    "files = glob.glob(os.path.join(\"staging\" + \"/*.csv\"))\n",
    "for file in files:\n",
    "    database = pd.read_csv(file)\n",
    "    database.columns.values[0] = 'c_'\n",
    "    for i in range(0, len(database.columns.values)):\n",
    "        database.columns.values[i] = transform(database.columns.values[i])\n",
    "    database.to_sql(name = file[8:-4], con = connex, if_exists='replace' ,dtype = 'TEXT', index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Downloads the ranking of hospitals and list of states that we need to focus.\n",
    "import requests\n",
    "url_1 = \"http://kevincrook.com/utd/hospital_ranking_focus_states.xlsx\"\n",
    "resp = requests.get(url_1)\n",
    "with open('hospital_ranking_focus_states.xlsx', 'wb') as output:\n",
    "    output.write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transforms the column values of the hospital rankings and focus states.\n",
    "import os\n",
    "dir_path = os.path.abspath(os.path.realpath('hospital_ranking_focus_states.xlsx'))\n",
    "hosp_rank_states = pd.ExcelFile(dir_path)\n",
    "df1 = hosp_rank_states.parse('Hospital National Ranking')\n",
    "df2 = hosp_rank_states.parse('Focus States')\n",
    "sheets = [df1,df2]\n",
    "for sheet in sheets:\n",
    "    for i in range(0,len(sheet.columns.values)):\n",
    "        sheet.columns.values[i] = transform(sheet.columns.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adds  hospital rankings and focus states to the DB.\n",
    "df1.to_sql(name = 'hospital_national_ranking', con = connex, if_exists='replace' ,dtype = 'INTEGER', index = False)\n",
    "df2.to_sql(name = 'focus_states', con = connex, if_exists='replace' ,dtype = 'TEXT', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Runs a query which gives us the top 100 hospitals nationwide\n",
    "sql = \"SELECT hospital_national_ranking.provider_id AS 'Provider ID', \\\n",
    "       hospital_general_information.hospital_name AS 'Hospital Name', \\\n",
    "       hospital_general_information.city AS 'City', \\\n",
    "       hospital_general_information.state AS 'State', \\\n",
    "       hospital_general_information.county_name AS 'County' \\\n",
    "       FROM hospital_national_ranking \\\n",
    "       INNER JOIN hospital_general_information ON \\\n",
    "       hospital_national_ranking.provider_id = hospital_general_information.provider_id \\\n",
    "       WHERE hospital_national_ranking.ranking < 101 \\\n",
    "       ORDER BY hospital_national_ranking.ranking;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reads the output of above query in the DB and writes it to excel\n",
    "df = pd.read_sql_query(sql,connex)\n",
    "writer = pd.ExcelWriter('hospital_ranking.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Nationwide', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sort all the values of state since we need the excel file hat we generate in alphabetical order\n",
    "#Runs a loop where the sql query will give us the details for each state one by one and then add it to excel.\n",
    "#Gives us the top 100 hospitals state wise\n",
    "df2.sort_values('state_name', inplace = True)\n",
    "for i in range (0, len(df2)):\n",
    "    sql_state = \"SELECT hospital_national_ranking.provider_id AS 'Provider ID', \\\n",
    "       hospital_general_information.hospital_name AS 'Hospital Name', \\\n",
    "       hospital_general_information.city AS 'City', \\\n",
    "       hospital_general_information.state AS 'State', \\\n",
    "       hospital_general_information.county_name AS 'County'\\\n",
    "       FROM hospital_national_ranking \\\n",
    "       INNER JOIN hospital_general_information ON \\\n",
    "       hospital_national_ranking.provider_id = hospital_general_information.provider_id \\\n",
    "       WHERE hospital_general_information.state LIKE \" +\"'\" + df2['state_abbreviation'][i] +\"'\" \\\n",
    "       +\" ORDER BY hospital_national_ranking.ranking LIMIT 100;\"\n",
    "    df_states = pd.read_sql_query(sql_state,connex)\n",
    "    df_states.to_excel(writer, sheet_name= df2['state_name'][i], index = False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This query gives us the measure id, measure name and scores for every measure which will be used for aggregation.\n",
    "sql_measure = \"SELECT \\\n",
    "              measure_id AS 'Measure ID',measure_name AS 'Measure Name', score  \\\n",
    "              FROM timely_and_effective_care___hospital WHERE \\\n",
    "              length(score) < 6;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below 5 cells do the pre-processing before writing the data to measure_statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(sql_measure,connex)\n",
    "#Required to convet the score to float since some of the values are not parsed if not converted.\n",
    "df['score'] = df['score'].astype(float)\n",
    "measure_details = df.copy()\n",
    "del measure_details['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = df.groupby(['Measure ID','Measure Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_group = (group.agg([np.min, np.max, np.mean, np.std]).rename(columns={'amin':'Minimum','amax': 'Maximum','mean': 'Average','std': 'Standard Deviation'}))\n",
    "test = df_group.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After running the aggregation method, it gives us a dataframe that is not uniform. \n",
    "#Using iloc, All the records are appended to the list.\n",
    "#reset index is used since aggregate function gives us the ununiform column headers.\n",
    "records = []\n",
    "for i in range (0, len(test)):\n",
    "    records.append(test.iloc[i].reset_index(drop = True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts the list that we created in the above cell to a dataframe.\n",
    "#reset_index is required since it gives us the measure ID, measure name in a single column which is then removed.\n",
    "Measure_statistics = pd.DataFrame(records)\n",
    "Measure_statistics.reset_index(inplace = True)\n",
    "del Measure_statistics['index']\n",
    "#Merges the measure id and measure name with the aggregate scores.\n",
    "#Since the both the dataframe are sorted we merge them by index and that gives us the Final dataframe that we need to...\n",
    "#... write to excel\n",
    "Final = pd.merge(measure_details, Measure_statistics, right_index = True, left_index = True)\n",
    "#renames the column named 0(ZERO) to Minimum\n",
    "Final.rename(index=str, columns={0: \"Minimum\", 1:'Maximum', 2:'Average',3:'Standard Deviation'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('measure_statistics.xlsx', engine='xlsxwriter')\n",
    "Final.to_excel(writer, sheet_name ='Nationwide' ,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the pre processing that we did for Nationwide scores, in the next cell it is done for each state. For loop is run which will take each state one by one, get the scores and group them. Later it will run the aggregate function and format it one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(df2)):\n",
    "    sql_measure = \"SELECT \\\n",
    "              measure_id AS 'Measure ID',measure_name AS 'Measure Name', score \\\n",
    "              FROM timely_and_effective_care___hospital \\\n",
    "              INNER JOIN hospital_general_information ON \\\n",
    "              timely_and_effective_care___hospital.provider_id = hospital_general_information.provider_id  \\\n",
    "               WHERE \\\n",
    "              length(score) < 6 AND hospital_general_information.state LIKE \" +\"'\" + df2['state_abbreviation'][i] +\"';\"\n",
    "    df = pd.read_sql_query(sql_measure,connex)\n",
    "    df['score'] = df['score'].astype(float)\n",
    "    measure_details = df.copy()\n",
    "    del measure_details['score']\n",
    "    group = df.groupby(['Measure ID','Measure Name'])\n",
    "    df_group = (group.agg([np.min, np.max, np.mean, np.std]).rename(columns={'amin':'Minimum','amax': 'Maximum','mean': 'Average','std': 'Standard Deviation'}))\n",
    "    test = df_group.copy()\n",
    "    records = []\n",
    "    for j in range (0, len(test)):\n",
    "        records.append(test.iloc[j].reset_index(drop = True))\n",
    "    Measure_statistics = pd.DataFrame(records)\n",
    "    Measure_statistics.reset_index(inplace = True)\n",
    "    del Measure_statistics['index']\n",
    "    Final_states = pd.merge(measure_details, Measure_statistics, right_index = True, left_index = True)\n",
    "    Final_states.rename(index=str, columns={0: \"Minimum\", 1:'Maximum', 2:'Average',3:'Standard Deviation'},inplace = True) \n",
    "    test = Final_states.copy()\n",
    "    test.to_excel(writer, sheet_name= df2['state_name'][i], index = False)\n",
    "writer.save()            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
